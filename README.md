# ğŸ›¡ï¸ Cloud Architecture Security Analyzer

AnÃ¡lise automatizada de seguranÃ§a de arquiteturas cloud usando **YOLO** para detecÃ§Ã£o de componentes e **STRIDE** para modelagem de ameaÃ§as.

## ğŸ“‹ VisÃ£o Geral

Este projeto detecta componentes em diagramas de arquitetura cloud (AWS, Azure, GCP) e aplica a metodologia STRIDE para identificar ameaÃ§as e sugerir mitigaÃ§Ãµes.

## ğŸ—ï¸ Estrutura do Projeto

```
cloud-arch-security-mvp/
â”œâ”€â”€ config/                     # ConfiguraÃ§Ãµes centralizadas
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ data/                       # Dados (ignorado no git)
â”‚   â””â”€â”€ diagrams/
â”œâ”€â”€ models/                     # Pesos do modelo YOLO
â”‚   â””â”€â”€ best.pt
â”œâ”€â”€ scripts/                    # Scripts utilitÃ¡rios
â”‚   â”œâ”€â”€ analyze_dataset.py
â”‚   â””â”€â”€ prepare_dataset.py
â”œâ”€â”€ sql/                        # Scripts SQL
â”‚   â””â”€â”€ init_db.sql
â”œâ”€â”€ src/                        # CÃ³digo fonte
â”‚   â”œâ”€â”€ app.py                  # Interface Streamlit
â”‚   â”œâ”€â”€ database.py             # Camada de persistÃªncia
â”‚   â”œâ”€â”€ detection/              # MÃ³dulo de detecÃ§Ã£o YOLO
â”‚   â”‚   â””â”€â”€ detector.py
â”‚   â”œâ”€â”€ stride/                 # MÃ³dulo de anÃ¡lise STRIDE
â”‚   â”‚   â”œâ”€â”€ categories.py
â”‚   â”‚   â”œâ”€â”€ engine.py
â”‚   â”‚   â””â”€â”€ knowledge_base.py
â”‚   â””â”€â”€ training/               # MÃ³dulo de treinamento
â”‚       â””â”€â”€ trainer.py
â”œâ”€â”€ tests/                      # Testes automatizados
â”‚   â”œâ”€â”€ test_detector.py
â”‚   â”œâ”€â”€ test_knowledge_base.py
â”‚   â””â”€â”€ test_stride_engine.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Makefile
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### 1. InstalaÃ§Ã£o

```bash
# Clonar o repositÃ³rio
git clone <repo-url>
cd fiap-hackaton-fase05

# Instalar dependÃªncias
pip install -e .

# Para desenvolvimento
pip install -e ".[dev]"
```

### 2. ConfiguraÃ§Ã£o

<details>
<summary><strong>ğŸ§ Linux / macOS</strong></summary>

```bash
# Copiar configuraÃ§Ãµes de ambiente
cp .env.example .env

# Editar conforme necessÃ¡rio
nano .env
```

</details>

<details>
<summary><strong>ğŸªŸ Windows (PowerShell)</strong></summary>

```powershell
# Copiar configuraÃ§Ãµes de ambiente
Copy-Item .env.example .env

# Editar conforme necessÃ¡rio
notepad .env
```

</details>

### 3. Modelo

Coloque o arquivo `best.pt` (modelo YOLO treinado) na pasta `models/`.

### 4. Banco de Dados (opcional)

> **Nota:** Se vocÃª deseja utilizar a funcionalidade de **histÃ³rico de anÃ¡lises**, Ã© necessÃ¡rio que o PostgreSQL esteja em execuÃ§Ã£o. Sem o banco de dados, o sistema nÃ£o consegue armazenar nem recuperar anÃ¡lises anteriores.

<details>
<summary><strong>ğŸ§ Linux / macOS</strong></summary>

```bash
# Subir PostgreSQL com Docker
make db-up
```

</details>

<details>
<summary><strong>ğŸªŸ Windows (PowerShell)</strong></summary>

```powershell
# Subir PostgreSQL com Docker
docker compose up -d
```

</details>

> **NÃ£o Ã© necessÃ¡rio executar o script `init_db.sql` manualmente.** O `docker-compose.yml` jÃ¡ monta esse arquivo na pasta `/docker-entrypoint-initdb.d/` do container PostgreSQL, o que faz com que ele seja executado automaticamente na primeira vez que o container Ã© criado. Basta subir o container e as tabelas serÃ£o criadas sozinhas.

### 5. Executar

<details>
<summary><strong>ğŸ§ Linux / macOS</strong></summary>

```bash
# Via Makefile
make run

# Ou diretamente
streamlit run src/app.py
```

</details>

<details>
<summary><strong>ğŸªŸ Windows (PowerShell)</strong></summary>

```powershell
streamlit run src/app.py
```

</details>

## ğŸ§ª Testes

<details>
<summary><strong>ğŸ§ Linux / macOS (Make)</strong></summary>

```bash
# Executar testes
make test

# Com cobertura
make test-cov

# Linting
make lint

# FormataÃ§Ã£o
make format
```

</details>

<details>
<summary><strong>ğŸªŸ Windows (PowerShell)</strong></summary>

```powershell
# Executar testes
pytest

# Com cobertura
pytest --cov=src --cov-report=html

# Linting
ruff check src/ tests/ config/
ruff format --check src/ tests/ config/

# FormataÃ§Ã£o
ruff format src/ tests/ config/
ruff check --fix src/ tests/ config/
```

</details>

## ğŸ”§ Treinamento

O treinamento do modelo foi realizado no **Google Colab** utilizando o notebook [`notebooks/train_colab.ipynb`](notebooks/train_colab.ipynb), que jÃ¡ contÃ©m todas as etapas de preparaÃ§Ã£o e treinamento configuradas para rodar na GPU gratuita do Colab.

**Alternativa local (requer GPU):** Se vocÃª possui uma GPU com recursos suficientes, pode realizar o treinamento localmente:

```bash
# Preparar dataset
python scripts/prepare_dataset.py

# Analisar dataset (estatÃ­sticas e distribuiÃ§Ã£o de classes)
python scripts/analyze_dataset.py

# Treinar modelo
python -m src.training.trainer --data path/to/data.yaml --epochs 30
```

## ğŸ“Š Categorias Detectadas

| Categoria | Exemplos |
|-----------|----------|
| Compute | EC2, Lambda, EKS, Fargate, Beanstalk, Cloud Run |
| Database | RDS, DynamoDB, Aurora, Redis, Cosmos DB, Firestore |
| Storage | S3, EBS, EFS, Glacier, Blob Storage, Cloud Storage |
| Network | VPC, CloudFront, Route 53, ELB, ALB, NLB, CDN |
| Security | WAF, KMS, GuardDuty, Shield, Secrets Manager, Firewall |
| Identity | IAM, Cognito, Active Directory Service |
| API Gateway | API Gateway, AppSync, Apigee |
| Messaging | SQS, SNS, EventBridge, Kinesis, Pub/Sub |
| Monitoring | CloudWatch, CloudTrail, X-Ray, Grafana, Prometheus |
| ML/AI | SageMaker, Rekognition, Comprehend, Vertex AI |
| DevOps | CodePipeline, CodeBuild, Jenkins, Terraform |
| Serverless | Amplify, Step Functions, AppFlow |
| Analytics | Athena, Glue, BigQuery, EMR |
| Groups | Availability Zone, Region |

##  LicenÃ§a

MIT