{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renato-penna/fiap-hackaton-fase05/blob/main/train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "k_IOsyC9OoKb",
        "outputId": "1e283aba-ff8e-4637-9242-88be4498bd1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGfroJQH3i3y",
        "outputId": "0622baf2-776d-4ce0-f200-89ac663803af"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "GDE0h6BEr3iq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372300ce-daff-485e-d3a7-e21d88319b83"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.4.8)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch<2.10,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.10,>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.10,>=1.8.0->ultralytics) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.callbacks import add_integration_callbacks\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import os\n",
        "import yaml\n",
        "import glob\n",
        "import time\n",
        "import threading\n",
        "\n",
        "# =========================================================\n",
        "# 0. Mount Google Drive\n",
        "# =========================================================\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive/colab\"\n",
        "PROJECT_NAME = \"cloud-arch-security-mvp\"\n",
        "\n",
        "DRIVE_PROJECT = f\"{DRIVE_ROOT}/{PROJECT_NAME}\"\n",
        "DRIVE_DATASET = f\"{DRIVE_PROJECT}/dataset\"\n",
        "DRIVE_CHECKPOINTS = f\"{DRIVE_PROJECT}/checkpoints\"  # <-- NOVO: pasta de checkpoints\n",
        "\n",
        "CONTENT_PROJECT = \"/content/yolo-project\"\n",
        "CONTENT_DATASET = f\"{CONTENT_PROJECT}/dataset\"\n",
        "\n",
        "# Cria pasta de checkpoints se nÃ£o existir\n",
        "os.makedirs(DRIVE_CHECKPOINTS, exist_ok=True)\n",
        "\n",
        "# =========================================================\n",
        "# 1. Preparar ambiente rÃ¡pido (/content)\n",
        "# =========================================================\n",
        "if Path(CONTENT_PROJECT).exists():\n",
        "    shutil.rmtree(CONTENT_PROJECT)\n",
        "\n",
        "os.makedirs(CONTENT_PROJECT, exist_ok=True)\n",
        "\n",
        "print(\"â³ Copiando dataset para disco local (SSD)...\")\n",
        "shutil.copytree(DRIVE_DATASET, CONTENT_DATASET)\n",
        "print(\"âœ… Dataset copiado!\")\n",
        "\n",
        "%cd /content/yolo-project\n",
        "\n",
        "# =========================================================\n",
        "# 2. Analisar e Filtrar Classes (NOVO - CRÃTICO)\n",
        "# =========================================================\n",
        "print(\"\\nğŸ“Š Analisando distribuiÃ§Ã£o de classes...\")\n",
        "\n",
        "# Carrega o data.yaml original\n",
        "with open(\"dataset/data.yaml\", \"r\") as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "\n",
        "original_names = data_config['names']\n",
        "print(f\"Total de classes original: {len(original_names)}\")\n",
        "\n",
        "# Conta ocorrÃªncias de cada classe no train\n",
        "from collections import Counter\n",
        "class_counts = Counter()\n",
        "\n",
        "train_labels_path = Path(\"dataset/train/labels\")\n",
        "for label_file in train_labels_path.glob(\"*.txt\"):\n",
        "    with open(label_file, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if parts:\n",
        "                class_id = int(parts[0])\n",
        "                class_counts[class_id] += 1\n",
        "\n",
        "# Define threshold mÃ­nimo (classes com menos de 10 amostras serÃ£o agrupadas)\n",
        "MIN_SAMPLES = 10\n",
        "rare_classes = [cid for cid, count in class_counts.items() if count < MIN_SAMPLES]\n",
        "print(f\"âš ï¸ Classes com menos de {MIN_SAMPLES} amostras: {len(rare_classes)}\")\n",
        "\n",
        "# Lista as classes mais problemÃ¡ticas\n",
        "print(\"\\nğŸ” Top 20 classes com menos amostras:\")\n",
        "for cid, count in sorted(class_counts.items(), key=lambda x: x[1])[:20]:\n",
        "    if cid < len(original_names):\n",
        "        print(f\"  ID {cid}: {original_names[cid]} - {count} amostras\")\n",
        "\n",
        "# =========================================================\n",
        "# 3. EstratÃ©gia: Agrupar classes raras em categorias\n",
        "# =========================================================\n",
        "# Vamos criar um mapeamento simplificado focado em componentes de seguranÃ§a\n",
        "# Isso melhora a generalizaÃ§Ã£o do modelo\n",
        "\n",
        "CATEGORY_MAPPING = {\n",
        "    # ComputaÃ§Ã£o\n",
        "    'compute': ['EC2', 'Lambda', 'EKS', 'Fargate', 'Container', 'Elastic Container Service',\n",
        "                'Elastic Container Registry', 'ECS', 'App gateway', 'Server', 'Vm Scaleset'],\n",
        "\n",
        "    # Bancos de Dados\n",
        "    'database': ['RDS', 'DynamoDB', 'Aurora', 'DocumentDB', 'ElastiCache', 'Redis',\n",
        "                 'Memcached', 'MySQL', 'PostgreSQL', 'Neptune', 'Redshift', 'Table',\n",
        "                 'Oracle DB', 'Mongo DB', 'DB'],\n",
        "\n",
        "    # Armazenamento\n",
        "    'storage': ['S3', 'EBS', 'EFS', 'Glacier', 'Storage Gateway', 'File share',\n",
        "                'Snowball', 'DataSync', 'Backup', 'Azure Storage - Files mobtmh'],\n",
        "\n",
        "    # Rede\n",
        "    'network': ['VPC Router', 'Internet Gateway', 'NAT Gateway', 'Transit Gateway',\n",
        "                'Direct Connect', 'Private Link', 'V-net', 'Private Subnet',\n",
        "                'Public Subnet', 'Availability Zone', 'Region', 'Endpoint',\n",
        "                'Network Firewall', 'Network Adapter', 'Customer Gateway', 'VP Gateway'],\n",
        "\n",
        "    # SeguranÃ§a\n",
        "    'security': ['IAM', 'IAM Role', 'Cognito', 'WAF', 'Firewall', 'Shield', 'GuardDuty',\n",
        "                 'Inspector Agent', 'Security Hub', 'Secrets Manager', 'Key Management Service',\n",
        "                 'CloudHSM', 'Certificate Manager', 'Macie', 'Detective', 'Key vault',\n",
        "                 'Security Group', 'Firewall Manager', 'Config', 'Trusted Advisor'],\n",
        "\n",
        "    # API e Gateway\n",
        "    'api_gateway': ['API-Gateway', 'Appsync', 'ALB', 'ELB', 'Cloudfront', 'CDN',\n",
        "                    'Route53', 'Cloud Map', 'Distribution', 'Edge Location'],\n",
        "\n",
        "    # Mensageria e Eventos\n",
        "    'messaging': ['SQS', 'SNS', 'EventBridge', 'Event Bus', 'MQ', 'Kinesis Data Streams',\n",
        "                  'Step Function'],\n",
        "\n",
        "    # Monitoramento\n",
        "    'monitoring': ['Cloud Watch', 'CloudWatch Alarm', 'Cloud Trail', 'X-Ray',\n",
        "                   'Azure monitor', 'Grafana', 'Prometheus', 'Flow logs'],\n",
        "\n",
        "    # Identidade\n",
        "    'identity': ['AAD', 'Active Directory Service', 'Sign-On', 'Users', 'Client'],\n",
        "\n",
        "    # ML/AI\n",
        "    'ml_ai': ['Sagemaker', 'Rekognition', 'Comprehend', 'Lex', 'Textract',\n",
        "              'Transcribe', 'Translate', 'Machine Learning', 'Notebook'],\n",
        "\n",
        "    # DevOps/CI-CD\n",
        "    'devops': ['CodePipeline', 'CodeBuild', 'CodeCommit', 'CodeDeploy', 'Jenkins',\n",
        "               'Github', 'Git', 'Docker Image', 'Image Builder', 'CloudFormation Stack',\n",
        "               'Terraform', 'Deploy Stage', 'Build Environment'],\n",
        "\n",
        "    # Serverless\n",
        "    'serverless': ['Lambda', 'Fargate', 'Amplify', 'AppFlow'],\n",
        "\n",
        "    # Grupos/Boundaries (importante para STRIDE)\n",
        "    'groups': ['groups', 'Region', 'Availability Zone', 'VPC Router']\n",
        "}\n",
        "\n",
        "# Inverte o mapeamento para lookup rÃ¡pido\n",
        "name_to_category = {}\n",
        "for category, names in CATEGORY_MAPPING.items():\n",
        "    for name in names:\n",
        "        name_to_category[name] = category\n",
        "\n",
        "# Cria novo mapeamento de classes (categorias simplificadas)\n",
        "SIMPLIFIED_NAMES = list(CATEGORY_MAPPING.keys()) + ['other']  # +1 para \"other\"\n",
        "print(f\"\\nâœ… Classes simplificadas: {len(SIMPLIFIED_NAMES)}\")\n",
        "print(f\"   {SIMPLIFIED_NAMES}\")\n",
        "\n",
        "# =========================================================\n",
        "# 4. Remapear labels para as novas categorias\n",
        "# =========================================================\n",
        "print(\"\\nğŸ”„ Remapeando labels para categorias simplificadas...\")\n",
        "\n",
        "def remap_label_file(label_path, original_names, name_to_category, simplified_names):\n",
        "    \"\"\"Remapeia um arquivo de labels para as novas categorias.\"\"\"\n",
        "    new_lines = []\n",
        "    with open(label_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                old_class_id = int(parts[0])\n",
        "                if old_class_id < len(original_names):\n",
        "                    old_name = original_names[old_class_id]\n",
        "                    # Encontra a categoria\n",
        "                    category = name_to_category.get(old_name, 'other')\n",
        "                    new_class_id = simplified_names.index(category)\n",
        "                    # ReconstrÃ³i a linha com novo ID\n",
        "                    new_line = f\"{new_class_id} {' '.join(parts[1:])}\\n\"\n",
        "                    new_lines.append(new_line)\n",
        "\n",
        "    # Sobrescreve o arquivo\n",
        "    with open(label_path, \"w\") as f:\n",
        "        f.writelines(new_lines)\n",
        "\n",
        "# Aplica remapeamento em todas as pastas\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    labels_path = Path(f\"dataset/{split}/labels\")\n",
        "    if labels_path.exists():\n",
        "        for label_file in labels_path.glob(\"*.txt\"):\n",
        "            remap_label_file(label_file, original_names, name_to_category, SIMPLIFIED_NAMES)\n",
        "        print(f\"  âœ… {split}/labels remapeado\")\n",
        "\n",
        "# =========================================================\n",
        "# 5. Atualizar data.yaml com novas classes\n",
        "# =========================================================\n",
        "new_data_config = {\n",
        "    'train': '../train/images',\n",
        "    'val': '../valid/images',\n",
        "    'test': '../test/images',\n",
        "    'nc': len(SIMPLIFIED_NAMES),\n",
        "    'names': SIMPLIFIED_NAMES\n",
        "}\n",
        "\n",
        "with open(\"dataset/data.yaml\", \"w\") as f:\n",
        "    yaml.dump(new_data_config, f, default_flow_style=False)\n",
        "\n",
        "print(f\"\\nâœ… data.yaml atualizado com {len(SIMPLIFIED_NAMES)} categorias!\")\n",
        "\n",
        "# =========================================================\n",
        "# 6. VERIFICAR SE HÃ CHECKPOINT PARA RETOMAR (NOVO!)\n",
        "# =========================================================\n",
        "print(\"\\nğŸ” Verificando checkpoints anteriores...\")\n",
        "\n",
        "checkpoint_files = sorted(glob.glob(f\"{DRIVE_CHECKPOINTS}/epoch*.pt\"))\n",
        "last_checkpoint = None\n",
        "resume_epoch = 0\n",
        "\n",
        "if checkpoint_files:\n",
        "    # Pega o checkpoint mais recente\n",
        "    last_checkpoint = checkpoint_files[-1]\n",
        "    # Extrai nÃºmero da Ã©poca do nome do arquivo (epoch_050.pt -> 50)\n",
        "    try:\n",
        "        resume_epoch = int(Path(last_checkpoint).stem.split('_')[1])\n",
        "        print(f\"âœ… Checkpoint encontrado: {last_checkpoint}\")\n",
        "        print(f\"   Retomando da Ã©poca {resume_epoch}\")\n",
        "    except:\n",
        "        last_checkpoint = None\n",
        "\n",
        "# TambÃ©m verifica se hÃ¡ um last.pt para retomar\n",
        "if os.path.exists(f\"{DRIVE_CHECKPOINTS}/last.pt\"):\n",
        "    last_checkpoint = f\"{DRIVE_CHECKPOINTS}/last.pt\"\n",
        "    print(f\"âœ… Encontrado last.pt - serÃ¡ usado para retomar treinamento\")\n",
        "\n",
        "if not last_checkpoint:\n",
        "    print(\"ğŸ“­ Nenhum checkpoint encontrado - iniciando do zero\")\n",
        "\n",
        "# =========================================================\n",
        "# 7. CALLBACK PARA SALVAR CHECKPOINTS NO DRIVE (NOVO!)\n",
        "# =========================================================\n",
        "SAVE_EVERY_N_EPOCHS = 5  # Salva a cada 5 Ã©pocas\n",
        "\n",
        "def save_checkpoint_to_drive(trainer):\n",
        "    \"\"\"Callback que copia checkpoints para o Google Drive apÃ³s cada Ã©poca.\"\"\"\n",
        "    current_epoch = trainer.epoch + 1  # epoch Ã© 0-indexed\n",
        "\n",
        "    # Salva a cada N Ã©pocas\n",
        "    if current_epoch % SAVE_EVERY_N_EPOCHS == 0:\n",
        "        weights_dir = trainer.save_dir / \"weights\"\n",
        "\n",
        "        # Copia last.pt (checkpoint mais recente)\n",
        "        if (weights_dir / \"last.pt\").exists():\n",
        "            # Salva com nome da Ã©poca para histÃ³rico\n",
        "            epoch_name = f\"epoch_{current_epoch:03d}.pt\"\n",
        "            shutil.copy(\n",
        "                weights_dir / \"last.pt\",\n",
        "                f\"{DRIVE_CHECKPOINTS}/{epoch_name}\"\n",
        "            )\n",
        "            # TambÃ©m mantÃ©m last.pt atualizado para retomada fÃ¡cil\n",
        "            shutil.copy(\n",
        "                weights_dir / \"last.pt\",\n",
        "                f\"{DRIVE_CHECKPOINTS}/last.pt\"\n",
        "            )\n",
        "            print(f\"\\nğŸ’¾ Checkpoint salvo: {DRIVE_CHECKPOINTS}/{epoch_name}\")\n",
        "\n",
        "        # Copia best.pt se existir\n",
        "        if (weights_dir / \"best.pt\").exists():\n",
        "            shutil.copy(\n",
        "                weights_dir / \"best.pt\",\n",
        "                f\"{DRIVE_CHECKPOINTS}/best.pt\"\n",
        "            )\n",
        "\n",
        "# =========================================================\n",
        "# 8. Carregar modelo (YOLOv8 Nano - ideal para Colab Free)\n",
        "# =========================================================\n",
        "# YOLOv8n Ã© ideal para:\n",
        "# - Colab free tier (treina 3x mais rÃ¡pido que v11m)\n",
        "# - Dataset de Ã­cones (nÃ£o precisa de modelo pesado)\n",
        "# - Deploy leve no Streamlit (~6MB vs ~40MB)\n",
        "\n",
        "if last_checkpoint:\n",
        "    print(f\"\\nğŸ”„ Carregando checkpoint: {last_checkpoint}\")\n",
        "    model = YOLO(last_checkpoint)\n",
        "else:\n",
        "    print(\"\\nğŸ“¦ Carregando modelo base: yolov8n.pt\")\n",
        "    model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Registra o callback de salvamento\n",
        "model.add_callback(\"on_train_epoch_end\", save_checkpoint_to_drive)\n",
        "\n",
        "# =========================================================\n",
        "# 9. Treinar com configuraÃ§Ã£o OTIMIZADA para YOLOv8n\n",
        "# =========================================================\n",
        "print(\"\\nğŸš€ Iniciando treinamento otimizado (YOLOv8n)...\")\n",
        "if last_checkpoint:\n",
        "    print(f\"   Retomando da Ã©poca ~{resume_epoch}\")\n",
        "\n",
        "results = model.train(\n",
        "    data=\"dataset/data.yaml\",\n",
        "\n",
        "    # TREINAMENTO PRINCIPAL (otimizado para modelo nano)\n",
        "    epochs=150,           # Menos Ã©pocas (modelo menor converge mais rÃ¡pido)\n",
        "    patience=25,          # Early stopping\n",
        "    batch=32,             # Batch maior (modelo nano usa menos VRAM)\n",
        "    imgsz=640,            # MantÃ©m 640\n",
        "\n",
        "    # RETOMADA DE TREINAMENTO\n",
        "    resume=True if last_checkpoint else False,  # Retoma se houver checkpoint\n",
        "\n",
        "    # OTIMIZAÃ‡ÃƒO - CRÃTICO PARA DESBALANCEAMENTO\n",
        "    optimizer='AdamW',    # AdamW Ã© melhor para datasets pequenos/mÃ©dios\n",
        "    lr0=0.001,            # Learning rate inicial\n",
        "    lrf=0.01,             # Learning rate final (decay)\n",
        "    weight_decay=0.0005,  # RegularizaÃ§Ã£o L2\n",
        "    warmup_epochs=5,      # Warmup para estabilizar inÃ­cio\n",
        "    cos_lr=True,          # Cosine annealing LR (melhor convergÃªncia)\n",
        "\n",
        "    # AUGMENTAÃ‡ÃƒO AGRESSIVA (compensa desbalanceamento)\n",
        "    hsv_h=0.015,          # VariaÃ§Ã£o de Hue\n",
        "    hsv_s=0.7,            # VariaÃ§Ã£o de SaturaÃ§Ã£o\n",
        "    hsv_v=0.4,            # VariaÃ§Ã£o de Valor/Brilho\n",
        "    degrees=15,           # RotaÃ§Ã£o Â±15Â°\n",
        "    translate=0.1,        # TranslaÃ§Ã£o 10%\n",
        "    scale=0.5,            # Escala 50%\n",
        "    shear=0.0,            # Sem cisalhamento (distorce Ã­cones)\n",
        "    perspective=0.0,      # Sem perspectiva\n",
        "    flipud=0.0,           # Sem flip vertical (Ã­cones tÃªm orientaÃ§Ã£o)\n",
        "    fliplr=0.5,           # Flip horizontal 50%\n",
        "    mosaic=1.0,           # Mosaic augmentation\n",
        "    mixup=0.1,            # MixUp leve\n",
        "    copy_paste=0.1,       # Copy-paste augmentation\n",
        "\n",
        "    # LOSS E VALIDAÃ‡ÃƒO\n",
        "    cls=1.0,              # Peso da loss de classificaÃ§Ã£o\n",
        "    box=7.5,              # Peso da loss de bounding box\n",
        "    dfl=1.5,              # Distribution Focal Loss\n",
        "\n",
        "    # INFRAESTRUTURA\n",
        "    cache=True,           # Cache em RAM (muito mais rÃ¡pido!)\n",
        "    workers=4,            # Workers para dataloader\n",
        "    device=0,             # GPU\n",
        "    exist_ok=True,\n",
        "    plots=True,\n",
        "    save_period=5,        # Salva checkpoint a cada 5 Ã©pocas\n",
        "\n",
        "    # NOME DO EXPERIMENTO\n",
        "    name='train_mvp_optimized',\n",
        "    project='runs/detect',\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# 10. Salvar resultados FINAIS no Drive\n",
        "# =========================================================\n",
        "DEST_WEIGHTS = f\"{DRIVE_PROJECT}/weights_backup\"\n",
        "SOURCE_WEIGHTS = \"runs/detect/train_mvp_optimized/weights\"\n",
        "\n",
        "os.makedirs(DEST_WEIGHTS, exist_ok=True)\n",
        "\n",
        "print(\"\\nğŸ’¾ Salvando modelo treinado no Google Drive...\")\n",
        "\n",
        "if os.path.exists(f\"{SOURCE_WEIGHTS}/best.pt\"):\n",
        "    shutil.copy(f\"{SOURCE_WEIGHTS}/best.pt\", f\"{DEST_WEIGHTS}/best_optimized.pt\")\n",
        "    shutil.copy(f\"{SOURCE_WEIGHTS}/last.pt\", f\"{DEST_WEIGHTS}/last_optimized.pt\")\n",
        "\n",
        "    # TambÃ©m copia para a pasta de checkpoints (versÃ£o final)\n",
        "    shutil.copy(f\"{SOURCE_WEIGHTS}/best.pt\", f\"{DRIVE_CHECKPOINTS}/best_final.pt\")\n",
        "\n",
        "    # Salva tambÃ©m o mapeamento de classes para usar no app\n",
        "    with open(f\"{DEST_WEIGHTS}/class_mapping.yaml\", \"w\") as f:\n",
        "        yaml.dump({\n",
        "            'simplified_names': SIMPLIFIED_NAMES,\n",
        "            'category_mapping': CATEGORY_MAPPING\n",
        "        }, f)\n",
        "\n",
        "    print(f\"âœ… SUCESSO! Modelo salvo em: {DEST_WEIGHTS}/best_optimized.pt\")\n",
        "    print(f\"âœ… Mapeamento de classes salvo em: {DEST_WEIGHTS}/class_mapping.yaml\")\n",
        "    print(f\"âœ… Checkpoints disponÃ­veis em: {DRIVE_CHECKPOINTS}/\")\n",
        "else:\n",
        "    print(\"âš ï¸ Arquivo best.pt nÃ£o encontrado - verificar logs de treinamento\")\n",
        "\n",
        "# Copia logs e mÃ©tricas\n",
        "if os.path.exists(\"runs/detect/train_mvp_optimized\"):\n",
        "    shutil.copytree(\n",
        "        \"runs/detect/train_mvp_optimized\",\n",
        "        f\"{DRIVE_PROJECT}/runs_optimized\",\n",
        "        dirs_exist_ok=True\n",
        "    )\n",
        "    print(f\"âœ… Logs salvos em: {DRIVE_PROJECT}/runs_optimized\")\n",
        "\n",
        "# =========================================================\n",
        "# 11. Limpar checkpoints antigos (opcional - mantÃ©m Ãºltimos 3)\n",
        "# =========================================================\n",
        "print(\"\\nğŸ§¹ Limpando checkpoints antigos (mantendo Ãºltimos 3)...\")\n",
        "checkpoint_files = sorted(glob.glob(f\"{DRIVE_CHECKPOINTS}/epoch*.pt\"))\n",
        "if len(checkpoint_files) > 3:\n",
        "    for old_ckpt in checkpoint_files[:-3]:\n",
        "        os.remove(old_ckpt)\n",
        "        print(f\"   Removido: {Path(old_ckpt).name}\")\n",
        "print(\"âœ… Limpeza concluÃ­da!\")"
      ],
      "metadata": {
        "id": "8Qo0N6HbrDZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2820e94e-e9ea-412e-c3f7-a71c118775a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "â³ Copiando dataset para disco local (SSD)...\n",
            "âœ… Dataset copiado!\n",
            "/content/yolo-project\n",
            "\n",
            "ğŸ“Š Analisando distribuiÃ§Ã£o de classes...\n",
            "Total de classes original: 203\n",
            "âš ï¸ Classes com menos de 10 amostras: 111\n",
            "\n",
            "ğŸ” Top 20 classes com menos amostras:\n",
            "  ID 47: CodeDeploy - 1 amostras\n",
            "  ID 163: Security Hub - 1 amostras\n",
            "  ID 42: CloudHSM - 1 amostras\n",
            "  ID 141: Prometheus - 1 amostras\n",
            "  ID 101: Grafana - 1 amostras\n",
            "  ID 143: Quarkus - 1 amostras\n",
            "  ID 130: Network Adapter - 1 amostras\n",
            "  ID 127: MySQL - 1 amostras\n",
            "  ID 187: Twilio - 1 amostras\n",
            "  ID 115: Kibana - 1 amostras\n",
            "  ID 162: Security Group - 1 amostras\n",
            "  ID 177: Task Runner - 1 amostras\n",
            "  ID 67: DocumentDB - 1 amostras\n",
            "  ID 132: Notebook - 1 amostras\n",
            "  ID 37: Cloud Map - 1 amostras\n",
            "  ID 33: Call Recordings - 1 amostras\n",
            "  ID 52: Connect - 1 amostras\n",
            "  ID 53: Connect Contact Lens - 1 amostras\n",
            "  ID 32: Call Metrics - 1 amostras\n",
            "  ID 18: AppFlow - 1 amostras\n",
            "\n",
            "âœ… Classes simplificadas: 14\n",
            "   ['compute', 'database', 'storage', 'network', 'security', 'api_gateway', 'messaging', 'monitoring', 'identity', 'ml_ai', 'devops', 'serverless', 'groups', 'other']\n",
            "\n",
            "ğŸ”„ Remapeando labels para categorias simplificadas...\n",
            "  âœ… train/labels remapeado\n",
            "  âœ… valid/labels remapeado\n",
            "  âœ… test/labels remapeado\n",
            "\n",
            "âœ… data.yaml atualizado com 14 categorias!\n",
            "\n",
            "ğŸ” Verificando checkpoints anteriores...\n",
            "âœ… Checkpoint encontrado: /content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/epoch_135.pt\n",
            "   Retomando da Ã©poca 135\n",
            "âœ… Encontrado last.pt - serÃ¡ usado para retomar treinamento\n",
            "\n",
            "ğŸ”„ Carregando checkpoint: /content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/last.pt\n",
            "\n",
            "ğŸš€ Iniciando treinamento otimizado...\n",
            "   Retomando da Ã©poca ~135\n",
            "Ultralytics 8.4.8 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=1.0, compile=False, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=dataset/data.yaml, degrees=15, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=200, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=/content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/last.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train_mvp_optimized, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=/content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/last.pt, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/yolo-project/runs/detect/runs/detect/train_mvp_optimized, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 27.2MB/s 0.0s\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
            "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
            " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 23        [16, 19, 22]  1   1421818  ultralytics.nn.modules.head.Detect           [14, 16, None, [256, 512, 512]]\n",
            "YOLO11m summary: 232 layers, 20,063,802 parameters, 20,063,786 gradients, 68.2 GFLOPs\n",
            "\n",
            "Transferred 649/649 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 98.9MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 468.7Â±283.6 MB/s, size: 9.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo-project/dataset/train/labels... 4418 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4418/4418 2.2Kit/s 2.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo-project/dataset/train/labels.cache\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (5.0GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4418/4418 342.9it/s 12.9s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 204.3Â±113.4 MB/s, size: 20.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo-project/dataset/valid/labels... 412 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 412/412 1.2Kit/s 0.4s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo-project/dataset/valid/labels.cache\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.5GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 412/412 169.6it/s 2.4s\n",
            "Plotting labels to /content/yolo-project/runs/detect/runs/detect/train_mvp_optimized/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n",
            "Resuming training /content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/last.pt from epoch 135 to 200 total epochs\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/yolo-project/runs/detect/runs/detect/train_mvp_optimized\u001b[0m\n",
            "Starting training for 200 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    135/200      8.03G     0.7054     0.9736      1.119          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.6it/s 2:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 1.2it/s 10.9s\n",
            "                   all        412        490      0.962      0.943      0.972      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    136/200      8.13G     0.7065     0.9834      1.117          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.9s\n",
            "                   all        412        490      0.953       0.94      0.971      0.849\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    137/200      8.21G     0.7028     0.9877      1.118          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.8it/s 2:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490      0.957      0.942      0.969      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    138/200      8.17G     0.7027     0.9798      1.117          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.9s\n",
            "                   all        412        490      0.957      0.946      0.969      0.856\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    139/200      8.16G     0.6906     0.9525      1.109          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.8s\n",
            "                   all        412        490      0.961      0.943       0.97      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    140/200      8.14G     0.6921       0.95      1.104          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.8it/s 2:38\n",
            "\n",
            "ğŸ’¾ Checkpoint salvo: /content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/epoch_140.pt\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.0it/s 6.4s\n",
            "                   all        412        490       0.96      0.941      0.969      0.852\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    141/200      8.21G     0.7008      0.971      1.111          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490      0.962      0.941      0.969      0.852\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    142/200      8.21G     0.6961     0.9564      1.115          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.9s\n",
            "                   all        412        490      0.959      0.943      0.971       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    143/200      8.21G     0.6961     0.9578       1.11          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.8it/s 2:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.6s\n",
            "                   all        412        490      0.961      0.949       0.97      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    144/200      8.12G      0.689     0.9401      1.106         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490      0.963      0.951       0.97      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    145/200      8.21G     0.6887     0.9376      1.109         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.8it/s 2:38\n",
            "\n",
            "ğŸ’¾ Checkpoint salvo: /content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/epoch_145.pt\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490      0.962      0.952       0.97      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    146/200      8.16G     0.6805     0.9427      1.104          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.8s\n",
            "                   all        412        490      0.962       0.95       0.97      0.856\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    147/200       8.2G     0.6759     0.9207      1.094         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.8s\n",
            "                   all        412        490       0.96      0.952       0.97      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    148/200      8.12G     0.6726     0.9151      1.094          2        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490      0.958      0.952      0.969      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    149/200      8.22G     0.6743     0.9244      1.099          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.8it/s 2:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.9s\n",
            "                   all        412        490      0.953       0.95      0.969      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    150/200      8.21G     0.6849     0.9371      1.105         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:38\n",
            "\n",
            "ğŸ’¾ Checkpoint salvo: /content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/epoch_150.pt\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.8s\n",
            "                   all        412        490      0.936      0.956      0.967       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    151/200      8.18G     0.6694     0.9196      1.101          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 6.0s\n",
            "                   all        412        490      0.926      0.954      0.967      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    152/200      8.13G     0.6638     0.9014      1.094         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.8s\n",
            "                   all        412        490      0.925       0.95      0.967       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    153/200      8.22G     0.6664     0.9098      1.092          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490      0.933      0.951      0.966      0.848\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    154/200      8.16G     0.6606     0.8968      1.087          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.9s\n",
            "                   all        412        490      0.934      0.951      0.965      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    155/200      8.21G     0.6647     0.8972      1.085         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\n",
            "ğŸ’¾ Checkpoint salvo: /content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/epoch_155.pt\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.9s\n",
            "                   all        412        490      0.936       0.95      0.967      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    156/200      8.14G     0.6523     0.9063      1.081          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:40\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490      0.936      0.949      0.959      0.843\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    157/200      8.22G     0.6621     0.9057      1.085          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490      0.938       0.95       0.96      0.843\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    158/200      8.21G     0.6578     0.8868      1.084          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.9s\n",
            "                   all        412        490      0.937       0.95       0.96      0.846\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    159/200       8.2G     0.6544     0.9003      1.087          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490       0.94      0.944      0.967       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    160/200      8.13G     0.6548     0.8998      1.086          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\n",
            "ğŸ’¾ Checkpoint salvo: /content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/epoch_160.pt\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.0it/s 6.5s\n",
            "                   all        412        490      0.942      0.943      0.967      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    161/200       8.2G     0.6485     0.8759      1.078          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.9s\n",
            "                   all        412        490      0.934      0.947      0.967       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    162/200      8.18G     0.6545     0.8938      1.085          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 6.0s\n",
            "                   all        412        490      0.934      0.948      0.966       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    163/200       8.2G     0.6426     0.8843      1.078          1        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1it/s 6.0s\n",
            "                   all        412        490      0.942       0.94      0.967      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    164/200      8.14G     0.6455     0.8936      1.084          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490      0.945      0.941      0.967      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    165/200      8.19G     0.6454     0.8814      1.077          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:40\n",
            "\n",
            "ğŸ’¾ Checkpoint salvo: /content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/epoch_165.pt\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.0it/s 6.5s\n",
            "                   all        412        490      0.946      0.943      0.967      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    166/200       8.2G     0.6327     0.8583      1.073          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:40\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.8s\n",
            "                   all        412        490      0.948      0.944      0.967      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    167/200      8.22G     0.6429     0.8658       1.07          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 6.0s\n",
            "                   all        412        490      0.949      0.944      0.968       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    168/200      8.14G      0.648     0.8865      1.079         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:40\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490      0.948      0.946      0.968      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    169/200      8.21G     0.6436     0.8698      1.078          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.9s\n",
            "                   all        412        490      0.948      0.946      0.968      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    170/200      8.21G     0.6374     0.8615      1.069          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:38\n",
            "\n",
            "ğŸ’¾ Checkpoint salvo: /content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/epoch_170.pt\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.0it/s 6.4s\n",
            "                   all        412        490      0.949      0.946      0.968      0.852\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    171/200      8.19G     0.6418     0.8853      1.077          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.6s\n",
            "                   all        412        490      0.949      0.948      0.968      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    172/200      8.13G     0.6375     0.8624      1.073          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490      0.949      0.946      0.968      0.849\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    173/200      8.17G     0.6366     0.8859      1.082          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.2it/s 5.9s\n",
            "                   all        412        490      0.949      0.947      0.968      0.849\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    174/200      8.21G     0.6374     0.8754      1.074          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490      0.949      0.949      0.969      0.852\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    175/200      8.18G     0.6335     0.8623      1.075          4        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\n",
            "ğŸ’¾ Checkpoint salvo: /content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/epoch_175.pt\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.0it/s 6.5s\n",
            "                   all        412        490      0.949      0.949      0.968      0.852\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    176/200      8.15G     0.6249      0.849      1.063         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 277/277 1.7it/s 2:39\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.3it/s 5.7s\n",
            "                   all        412        490      0.949      0.949      0.969      0.854\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 30 epochs. Best results observed at epoch 146, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=30) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "42 epochs completed in 2.065 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 12. VALIDAÃ‡ÃƒO DO MODELO TREINADO (opcional)\n",
        "# =========================================================\n",
        "# Execute esta cÃ©lula APÃ“S o treinamento para validar o modelo\n",
        "# Funciona mesmo se a sessÃ£o reiniciou (busca do Google Drive)\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from pathlib import Path\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# ConfiguraÃ§Ã£o (precisa redefinir se sessÃ£o reiniciou)\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive/colab\"\n",
        "PROJECT_NAME = \"cloud-arch-security-mvp\"\n",
        "DRIVE_PROJECT = f\"{DRIVE_ROOT}/{PROJECT_NAME}\"\n",
        "DRIVE_CHECKPOINTS = f\"{DRIVE_PROJECT}/checkpoints\"\n",
        "DRIVE_DATASET = f\"{DRIVE_PROJECT}/dataset\"\n",
        "\n",
        "# Monta o Drive se ainda nÃ£o estiver montado\n",
        "from google.colab import drive\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# =========================================================\n",
        "# Encontrar o melhor modelo (local ou no Drive)\n",
        "# =========================================================\n",
        "print(\"\\nğŸ” Procurando modelo treinado...\")\n",
        "\n",
        "# Lista de possÃ­veis localizaÃ§Ãµes do modelo\n",
        "model_paths = [\n",
        "    \"runs/detect/train_mvp_optimized/weights/best.pt\",  # Local (se treino acabou de terminar)\n",
        "    f\"{DRIVE_CHECKPOINTS}/best.pt\",                      # Checkpoint no Drive\n",
        "    f\"{DRIVE_CHECKPOINTS}/best_final.pt\",                # VersÃ£o final no Drive\n",
        "    f\"{DRIVE_PROJECT}/weights_backup/best_optimized.pt\", # Backup no Drive\n",
        "]\n",
        "\n",
        "best_model_path = None\n",
        "for path in model_paths:\n",
        "    if os.path.exists(path):\n",
        "        best_model_path = path\n",
        "        print(f\"âœ… Modelo encontrado: {path}\")\n",
        "        break\n",
        "\n",
        "if not best_model_path:\n",
        "    print(\"âŒ Nenhum modelo encontrado!\")\n",
        "    print(\"   Verifique se o treinamento foi concluÃ­do e os arquivos salvos no Drive.\")\n",
        "    print(f\"   Pasta esperada: {DRIVE_CHECKPOINTS}/\")\n",
        "else:\n",
        "    # Carrega o modelo\n",
        "    val_model = YOLO(best_model_path)\n",
        "\n",
        "    # Verifica quantas classes o modelo tem\n",
        "    num_model_classes = len(val_model.names)\n",
        "    print(f\"ğŸ“Š Modelo tem {num_model_classes} classes\")\n",
        "\n",
        "    # =========================================================\n",
        "    # Preparar dataset de teste (se nÃ£o existe localmente)\n",
        "    # =========================================================\n",
        "    CONTENT_DATASET = \"/content/yolo-project/dataset\"\n",
        "\n",
        "    if not os.path.exists(CONTENT_DATASET):\n",
        "        print(\"\\nâ³ Copiando dataset do Drive para disco local...\")\n",
        "        os.makedirs(\"/content/yolo-project\", exist_ok=True)\n",
        "        shutil.copytree(DRIVE_DATASET, CONTENT_DATASET)\n",
        "        print(\"âœ… Dataset copiado!\")\n",
        "\n",
        "    # =========================================================\n",
        "    # Verificar compatibilidade de classes\n",
        "    # =========================================================\n",
        "    import yaml\n",
        "\n",
        "    with open(f\"{CONTENT_DATASET}/data.yaml\", \"r\") as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "\n",
        "    num_dataset_classes = data_config.get('nc', len(data_config.get('names', [])))\n",
        "    print(f\"ğŸ“Š Dataset tem {num_dataset_classes} classes\")\n",
        "\n",
        "    if num_model_classes != num_dataset_classes:\n",
        "        print(f\"\\nâš ï¸ INCOMPATIBILIDADE DETECTADA!\")\n",
        "        print(f\"   Modelo: {num_model_classes} classes\")\n",
        "        print(f\"   Dataset: {num_dataset_classes} classes\")\n",
        "        print(f\"\\nğŸ’¡ O modelo foi treinado com classes diferentes do dataset atual.\")\n",
        "        print(f\"   Isso acontece quando vocÃª treinou ANTES de aplicar o remapeamento.\")\n",
        "        print(f\"\\nğŸ”§ SOLUÃ‡Ã•ES:\")\n",
        "        print(f\"   1. Delete os checkpoints antigos e retreine com as novas classes\")\n",
        "        print(f\"   2. Ou valide apenas visualmente (pulando mÃ©tricas)\")\n",
        "\n",
        "        # Pula validaÃ§Ã£o formal, faz apenas teste visual\n",
        "        skip_validation = True\n",
        "    else:\n",
        "        skip_validation = False\n",
        "\n",
        "    # =========================================================\n",
        "    # ValidaÃ§Ã£o no conjunto de teste (se compatÃ­vel)\n",
        "    # =========================================================\n",
        "    if not skip_validation:\n",
        "        print(\"\\nğŸ§ª Validando modelo treinado...\")\n",
        "\n",
        "        val_results = val_model.val(\n",
        "            data=f\"{CONTENT_DATASET}/data.yaml\",\n",
        "            split=\"test\",\n",
        "            plots=True,\n",
        "            save_json=True\n",
        "        )\n",
        "\n",
        "        print(\"\\nğŸ“Š MÃ‰TRICAS DE VALIDAÃ‡ÃƒO:\")\n",
        "        print(f\"   mAP50: {val_results.box.map50:.4f}\")\n",
        "        print(f\"   mAP50-95: {val_results.box.map:.4f}\")\n",
        "        print(f\"   PrecisÃ£o: {val_results.box.mp:.4f}\")\n",
        "        print(f\"   Recall: {val_results.box.mr:.4f}\")\n",
        "\n",
        "        # Mostra mÃ©tricas por classe\n",
        "        print(\"\\nğŸ“ˆ mAP50 por categoria:\")\n",
        "        for i, name in enumerate(val_model.names.values()):\n",
        "            if i < len(val_results.box.ap50):\n",
        "                ap = val_results.box.ap50[i]\n",
        "                print(f\"   {name}: {ap:.4f}\")\n",
        "\n",
        "    # =========================================================\n",
        "    # 13. TESTE EM IMAGEM DE EXEMPLO (sempre funciona)\n",
        "    # =========================================================\n",
        "    print(\"\\nğŸ–¼ï¸ Testando em imagem de exemplo...\")\n",
        "\n",
        "    test_images = list(Path(f\"{CONTENT_DATASET}/test/images\").glob(\"*.jpg\")) + \\\n",
        "                  list(Path(f\"{CONTENT_DATASET}/test/images\").glob(\"*.png\"))\n",
        "\n",
        "    # TambÃ©m tenta do Drive diretamente\n",
        "    if not test_images:\n",
        "        test_images = list(Path(f\"{DRIVE_DATASET}/test/images\").glob(\"*.jpg\")) + \\\n",
        "                      list(Path(f\"{DRIVE_DATASET}/test/images\").glob(\"*.png\"))\n",
        "\n",
        "    if test_images:\n",
        "        # Seleciona imagem aleatÃ³ria\n",
        "        test_img = random.choice(test_images)\n",
        "        print(f\"   Imagem: {test_img.name}\")\n",
        "\n",
        "        # Executa inferÃªncia\n",
        "        test_results = val_model(str(test_img), conf=0.35, verbose=False)\n",
        "\n",
        "        # Mostra detecÃ§Ãµes\n",
        "        detected_classes = set()\n",
        "        for r in test_results:\n",
        "            for box in r.boxes:\n",
        "                cls_id = int(box.cls[0])\n",
        "                conf = float(box.conf[0])\n",
        "                cls_name = val_model.names[cls_id]\n",
        "                detected_classes.add(cls_name)\n",
        "                print(f\"   Detectado: {cls_name} (conf: {conf:.2f})\")\n",
        "\n",
        "        if not detected_classes:\n",
        "            print(\"   âš ï¸ Nenhum componente detectado. Tente outra imagem ou ajuste a confianÃ§a.\")\n",
        "\n",
        "        # Salva imagem com detecÃ§Ãµes\n",
        "        result_img = test_results[0].plot()\n",
        "        result_path = f\"{DRIVE_PROJECT}/test_detection.jpg\"\n",
        "\n",
        "        from PIL import Image\n",
        "        import numpy as np\n",
        "        img_pil = Image.fromarray(result_img)\n",
        "        img_pil.save(result_path)\n",
        "        print(f\"\\nâœ… Imagem de teste salva em: {result_path}\")\n",
        "\n",
        "        # Exibe no notebook\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(result_img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"DetecÃ§Ãµes: {', '.join(detected_classes) if detected_classes else 'Nenhuma'}\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"   âš ï¸ Nenhuma imagem de teste encontrada no dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "7gjYEekphbAL",
        "outputId": "ca6becba-6ea0-42a0-bfe7-29df0938ea69"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ” Procurando modelo treinado...\n",
            "âœ… Modelo encontrado: /content/drive/MyDrive/colab/cloud-arch-security-mvp/checkpoints/best.pt\n",
            "\n",
            "â³ Copiando dataset do Drive para disco local...\n",
            "âœ… Dataset copiado!\n",
            "\n",
            "ğŸ§ª Validando modelo treinado...\n",
            "Ultralytics 8.4.8 ğŸš€ Python-3.12.12 torch-2.9.0+cpu CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "YOLO11m summary (fused): 126 layers, 20,040,826 parameters, 0 gradients, 67.7 GFLOPs\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 15.8MB/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 136.6Â±87.6 MB/s, size: 8.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo-project/dataset/test/labels... 223 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 223/223 1.1Kit/s 0.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo-project/dataset/test/labels.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/14  50.8s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 202 is out of bounds for axis 1 with size 15",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1238827620.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m                         'ml_ai', 'devops', 'serverless', 'groups', 'other']\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     val_results = val_model.val(\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{CONTENT_DATASET}/data.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mval\u001b[0;34m(self, validator, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mvalidator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalidator\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mvalidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/validator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplots\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_val_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/val.py\u001b[0m in \u001b[0;36mupdate_metrics\u001b[0;34m(self, preds, batch)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"im_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py\u001b[0m in \u001b[0;36mprocess_batch\u001b[0;34m(self, detections, batch, conf, iou_thres)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0mdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# TP if class is correct else both an FP and an FN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 202 is out of bounds for axis 1 with size 15"
          ]
        }
      ]
    }
  ]
}